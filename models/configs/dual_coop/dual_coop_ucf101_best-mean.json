{
  "clip-model": "openai/clip-vit-base-patch16",
  "ctx-len": 8,
  "ctx-len-video": 8,
  "class-wise": false,
  "lr": 0.001,
  "weight-decay": 0.01,
  "std-init": 0.02,
  "num-temporal-views": 4,
  "num-spatial-views": 3,
  "num-frames-temporal": 8,
  "regularisation-strength": 0.0,
  "regularisation-text": "A video of a person doing",
  "cosine-regularisation-strength": 0.0,
  "use-handcrafted-features": false,
  "keep-vision-prompts-throughout": false,
  "temporal-pooling": "mean",
  "num-heads-attention-pooling": 1,
  "num-frames": null,
  "has-discriminative-conditioning": false,
  "space-between-frames": null,
  "epochs": 20,
  "start-train-step": 0,
  "epochs-to-skip": 0,
  "save-every-n-steps": 10000000000.0,
  "continue-from": null,
  "grad-norm-max": 1.0,
  "loss-function": "cross-entropy",
  "dataset-config": {
    "batch-size": 4,
    "num-workers": 4,
    "batches-per-backprop": 32,
    "split-file": "",
    "K-train": null,
    "K-val": null,
    "K-test": null,
    "split-function": "",
    "random-seed": 42,
    "has-validation": true,
    "use-cache": false,
    "resized-cache-protocol": null,
    "save-to-cache": false,
    "class-protocol": "all",
    "num-classes": null,
    "use-excess-for": "none",
    "remove-class-if-insufficient": false,
    "class-weights": null,
    "skip-first-K-train": 0,
    "skip-first-K-val": 0,
    "val-proportion": 0.2,
    "use-clips": false
  },
  "use-checkpointing": true,
  "debug": false,
  "use-profiling": false,
  "use-fresh-lr-scheduler": true,
  "learn-just-pooling": false,
  "checkpoint-last-n": 12,
  "log-every-n-steps": 10,
  "training-history": {
    "train-acc": [
      0.43713027061044685,
      0.7199496538703587,
      0.8157331655129012,
      0.8477029578351164,
      0.8752674638137193,
      0.891881686595343,
      0.909880427942102,
      0.9160478288231593,
      0.9252359974826935,
      0.9286343612334802,
      0.9405915670232851,
      0.9482693517935809,
      0.9515418502202643,
      0.9553178099433606,
      0.9594713656387666,
      0.963373190685966,
      0.9663939584644431,
      0.9680302076777848,
      0.970547514159849,
      0.9696664568911265
    ],
    "train-loss": [
      3.3186823965544368,
      1.6848252389474512,
      1.0880650418895532,
      0.8152513987767463,
      0.6665514130349276,
      0.5592312504916614,
      0.4815230257335588,
      0.4286632770708779,
      0.3814049655345343,
      0.3496557755467275,
      0.30861243313404657,
      0.282455277247876,
      0.2618245801211454,
      0.24600692566570956,
      0.23070660657744652,
      0.21616132578960826,
      0.20536697608558843,
      0.1996563747590859,
      0.19445991300051133,
      0.19207317335490087
    ],
    "val-acc": [
      0.6234256926952141,
      0.7984886649874056,
      0.8482367758186398,
      0.8444584382871536,
      0.8683879093198993,
      0.8759445843828715,
      0.8942065491183879,
      0.9005037783375315,
      0.8929471032745592,
      0.9212846347607053,
      0.9206549118387909,
      0.9181360201511335,
      0.9332493702770781,
      0.931360201511335,
      0.9319899244332494,
      0.9363979848866498,
      0.9338790931989924,
      0.9370277078085643,
      0.9345088161209067,
      0.9370277078085643
    ],
    "val-loss": [
      2.2537673196804615,
      1.2704745181261443,
      0.9411150215367226,
      0.7607492568342001,
      0.6205944127452464,
      0.5638539182252112,
      0.4964165260865158,
      0.45268827460715616,
      0.4258797520335285,
      0.3867510581220165,
      0.3581782193861489,
      0.3324725654431307,
      0.32506686542065866,
      0.3123801527896741,
      0.29868125087307107,
      0.28774996364010635,
      0.285880380892488,
      0.2797288125467672,
      0.2792405460771145,
      0.27741930487868316
    ]
  },
  "fp16": false,
  "grad-scaler-config": {
    "init-scale": 8192,
    "growth-factor": 2.0,
    "backoff-factor": 0.5,
    "growth-interval": 100
  },
  "activation-clamp-value": 10000.0,
  "method-name": "dual-coop",
  "prompt-optimisation-method": "dual_coop",
  "dataset": "ucf101",
  "data-dir": "/work3/fasco/data/raw/datasets/pevogam/ucf101/versions/1/UCF101/UCF-101",
  "model": "openai/clip-vit-base-patch16",
  "K": null,
  "val-examples-per-class": null,
  "batch-size": 4,
  "out": "/work3/fasco/data/processed/prompts/dual_coop/ucf101",
  "num-workers": 4,
  "re-process-data": false,
  "use-wandb": true,
  "num-head-attention-pooling": 1
}
{
  "clip-model": "openai/clip-vit-base-patch16",
  "ctx-len": 8,
  "ctx-len-video": 8,
  "class-wise": false,
  "lr": 8e-05,
  "weight-decay": 0.2,
  "std-init": 0.02,
  "num-temporal-views": 4,
  "num-spatial-views": 3,
  "num-frames-temporal": 8,
  "regularisation-strength": 0.0,
  "regularisation-text": "A video of a person doing",
  "cosine-regularisation-strength": 0.0,
  "use-handcrafted-features": false,
  "keep-vision-prompts-throughout": false,
  "temporal-pooling": "mean",
  "num-heads-attention-pooling": 1,
  "num-frames": 8,
  "has-discriminative-conditioning": false,
  "space-between-frames": null,
  "epochs": 20,
  "start-train-step": 0,
  "epochs-to-skip": 0,
  "save-every-n-steps": 10000000000.0,
  "continue-from": null,
  "grad-norm-max": 1.0,
  "loss-function": "cross-entropy",
  "dataset-config": {
    "batch-size": 4,
    "num-workers": 4,
    "batches-per-backprop": 32,
    "split-file": "",
    "K-train": null,
    "K-val": null,
    "K-test": null,
    "split-function": "",
    "random-seed": 42,
    "has-validation": true,
    "use-cache": false,
    "resized-cache-protocol": null,
    "save-to-cache": false,
    "class-protocol": "all",
    "num-classes": null,
    "use-excess-for": "none",
    "remove-class-if-insufficient": false,
    "class-weights": null,
    "skip-first-K-train": 0,
    "skip-first-K-val": 0,
    "val-proportion": 0.2,
    "use-clips": false
  },
  "use-checkpointing": false,
  "debug": false,
  "use-profiling": false,
  "use-fresh-lr-scheduler": true,
  "learn-just-pooling": false,
  "checkpoint-last-n": 12,
  "log-every-n-steps": 10,
  "training-history": {
    "train-acc": [
      0.19282567652611707,
      0.38892385147891756,
      0.5587161736941473,
      0.6750157331655129,
      0.7244808055380743,
      0.802391441157961,
      0.8387665198237886,
      0.8881057268722466,
      0.9118942731277533,
      0.9390811831340465,
      0.967023285084959,
      0.9855254877281309,
      0.9932032724984267,
      0.9986154814348647,
      0.9993706733794839,
      1.0,
      1.0,
      1.0,
      1.0,
      1.0
    ],
    "train-loss": [
      3.7510024976400254,
      2.404869660556954,
      1.6814343730333543,
      1.1660737639631844,
      0.9537876981395532,
      0.6680589084133103,
      0.5120808586375079,
      0.3565679820248584,
      0.2775292907292322,
      0.20638800321546572,
      0.11079150728642227,
      0.0572516257092216,
      0.02794288553630428,
      0.011403719864227698,
      0.004837423604265409,
      0.0023604429615901807,
      0.001555422044085436,
      0.0013683914463050416,
      0.0012920041141305952,
      0.0012129314895543458
    ],
    "val-acc": [
      0.31801007556675065,
      0.4363979848866499,
      0.6089420654911839,
      0.6693954659949622,
      0.7399244332493703,
      0.767632241813602,
      0.8299748110831234,
      0.8400503778337531,
      0.8740554156171285,
      0.9017632241813602,
      0.8986146095717884,
      0.9206549118387909,
      0.9269521410579346,
      0.948992443324937,
      0.9477329974811083,
      0.9502518891687658,
      0.9496221662468514,
      0.9508816120906801,
      0.9515113350125944,
      0.9515113350125944
    ],
    "val-loss": [
      2.856722959408757,
      2.1620012309920673,
      1.534398374481711,
      1.2681408265710548,
      0.9128048300511958,
      0.7566909404316541,
      0.5609452456996434,
      0.5137727542902483,
      0.41789525523143917,
      0.3334532651315362,
      0.3375393560913177,
      0.2484139523654341,
      0.26971205886594424,
      0.18499485992032663,
      0.1946695975040055,
      0.18915483946438333,
      0.18270252551139168,
      0.1832963925659704,
      0.1823679821009709,
      0.1822414226286255
    ]
  },
  "fp16": false,
  "grad-scaler-config": {
    "init-scale": 8192,
    "growth-factor": 2.0,
    "backoff-factor": 0.5,
    "growth-interval": 100
  },
  "activation-clamp-value": 10000.0,
  "method-name": "stt",
  "num-frame-tokens": 1,
  "num-heads-summary-attention": 12,
  "layers-with-summary-to-text": [
    0,
    1,
    2,
    3,
    4
  ],
  "prompt-optimisation-method": "stt",
  "dataset": "ucf101",
  "data-dir": "/work3/fasco/data/raw/datasets/pevogam/ucf101/versions/1/UCF101/UCF-101",
  "model": "openai/clip-vit-base-patch16",
  "K": null,
  "val-examples-per-class": null,
  "batch-size": 4,
  "out": "/work3/fasco/data/processed/prompts/stt/ucf101",
  "num-workers": 4,
  "re-process-data": false,
  "use-wandb": true,
  "num-head-attention-pooling": 1,
  "N-text-layers": 12,
  "N-vision-layers": 12
}
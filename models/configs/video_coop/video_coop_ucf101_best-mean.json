{
  "clip-model": "openai/clip-vit-base-patch16",
  "ctx-len": 8,
  "ctx-len-video": 0,
  "class-wise": false,
  "lr": 0.0008,
  "weight-decay": 0.001,
  "std-init": 0.02,
  "num-temporal-views": 4,
  "num-spatial-views": 3,
  "num-frames-temporal": 8,
  "regularisation-strength": 0.0,
  "regularisation-text": "A video of a person doing",
  "cosine-regularisation-strength": 0.0,
  "use-handcrafted-features": false,
  "keep-vision-prompts-throughout": false,
  "temporal-pooling": "mean",
  "num-heads-attention-pooling": 1,
  "num-frames": 8,
  "has-discriminative-conditioning": false,
  "space-between-frames": null,
  "epochs": 20,
  "start-train-step": 0,
  "epochs-to-skip": 0,
  "save-every-n-steps": 10000000000.0,
  "continue-from": null,
  "grad-norm-max": 1.0,
  "loss-function": "cross-entropy",
  "dataset-config": {
    "batch-size": 4,
    "num-workers": 4,
    "batches-per-backprop": 32,
    "split-file": "",
    "K-train": null,
    "K-val": null,
    "K-test": null,
    "split-function": "",
    "random-seed": 42,
    "has-validation": true,
    "use-cache": false,
    "resized-cache-protocol": null,
    "save-to-cache": false,
    "class-protocol": "all",
    "num-classes": null,
    "use-excess-for": "none",
    "remove-class-if-insufficient": false,
    "class-weights": null,
    "skip-first-K-train": 0,
    "skip-first-K-val": 0,
    "val-proportion": 0.2,
    "use-clips": false
  },
  "use-checkpointing": true,
  "debug": false,
  "use-profiling": false,
  "use-fresh-lr-scheduler": true,
  "learn-just-pooling": false,
  "checkpoint-last-n": 12,
  "log-every-n-steps": 10,
  "training-history": {
    "train-acc": [
      0.4280679672750157,
      0.6777847702957835,
      0.7407174323473883,
      0.7750786658275645,
      0.7957205789804909,
      0.8028949024543738,
      0.8140969162995595,
      0.8303335431088735,
      0.836626809314034,
      0.8424166142227816,
      0.8539962240402769,
      0.8482064191315293,
      0.8612964128382631,
      0.8693517935808684,
      0.8706104468219006,
      0.8766519823788547,
      0.881686595342983,
      0.8815607300188798,
      0.8857142857142857,
      0.8873505349276274
    ],
    "train-loss": [
      3.531342432347388,
      2.5487942003618627,
      2.150828449496539,
      1.9046034258967903,
      1.7089037425267464,
      1.5591390025173064,
      1.4542233716173694,
      1.3488570101085589,
      1.2652218376337319,
      1.2025568852265576,
      1.1266645197451228,
      1.0841398629247954,
      1.0464210735918817,
      1.0032909357300188,
      0.9788155999252675,
      0.9536199801368785,
      0.9364952284258968,
      0.9290036604192888,
      0.9201965293620201,
      0.9164546786500944
    ],
    "val-acc": [
      0.6007556675062973,
      0.7021410579345088,
      0.7575566750629723,
      0.7865239294710328,
      0.8041561712846348,
      0.7858942065491183,
      0.825566750629723,
      0.8419395465994962,
      0.8425692695214105,
      0.8387909319899244,
      0.8602015113350125,
      0.8476070528967254,
      0.8602015113350125,
      0.8494962216624685,
      0.8589420654911839,
      0.8646095717884131,
      0.8664987405541562,
      0.8671284634760705,
      0.8683879093198993,
      0.8702770780856424
    ],
    "val-loss": [
      2.8925364633050914,
      2.334679798980804,
      2.0378234541085867,
      1.821549667144002,
      1.6342892187368359,
      1.5561052665151938,
      1.4324794263022973,
      1.3165133003548952,
      1.2659443018193208,
      1.2037964165210724,
      1.1629056690321762,
      1.1164593602382866,
      1.074952387652109,
      1.0457466294618338,
      1.0151495076434438,
      1.0028156437148676,
      0.9904651621014104,
      0.9810129974215698,
      0.9753834314325294,
      0.9741744213650749
    ]
  },
  "fp16": false,
  "grad-scaler-config": {
    "init-scale": 8192,
    "growth-factor": 2.0,
    "backoff-factor": 0.5,
    "growth-interval": 100
  },
  "activation-clamp-value": 10000.0,
  "method-name": "video-coop",
  "prompt-optimisation-method": "video_coop",
  "dataset": "ucf101",
  "data-dir": "/work3/fasco/data/raw/datasets/pevogam/ucf101/versions/1/UCF101/UCF-101",
  "model": "openai/clip-vit-base-patch16",
  "K": null,
  "val-examples-per-class": null,
  "batch-size": 4,
  "out": "/work3/fasco/data/processed/prompts/video_coop/ucf101",
  "num-workers": 4,
  "re-process-data": false,
  "use-wandb": true,
  "num-head-attention-pooling": 1
}
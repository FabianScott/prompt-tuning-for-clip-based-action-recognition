{
  "clip-model": "openai/clip-vit-base-patch16",
  "ctx-len": 8,
  "ctx-len-video": 8,
  "class-wise": false,
  "lr": 8e-05,
  "weight-decay": 0.2,
  "std-init": 0.02,
  "num-temporal-views": 4,
  "num-spatial-views": 3,
  "num-frames-temporal": 8,
  "regularisation-strength": 0.0,
  "regularisation-text": "A video of a person doing",
  "cosine-regularisation-strength": 0.0,
  "use-handcrafted-features": false,
  "keep-vision-prompts-throughout": true,
  "temporal-pooling": "mean",
  "num-heads-attention-pooling": 1,
  "num-frames": 8,
  "has-discriminative-conditioning": true,
  "space-between-frames": null,
  "epochs": 20,
  "start-train-step": 0,
  "epochs-to-skip": 0,
  "save-every-n-steps": 10000000000.0,
  "continue-from": null,
  "grad-norm-max": 1.0,
  "loss-function": "cross-entropy",
  "dataset-config": {
    "batch-size": 4,
    "num-workers": 2,
    "batches-per-backprop": 32,
    "split-file": "",
    "K-train": null,
    "K-val": null,
    "K-test": null,
    "split-function": "",
    "random-seed": 42,
    "has-validation": true,
    "use-cache": false,
    "resized-cache-protocol": null,
    "save-to-cache": false,
    "class-protocol": "all",
    "num-classes": null,
    "use-excess-for": "none",
    "remove-class-if-insufficient": false,
    "class-weights": null,
    "skip-first-K-train": 0,
    "skip-first-K-val": 0,
    "val-proportion": 0.2,
    "use-clips": false
  },
  "use-checkpointing": false,
  "debug": false,
  "use-profiling": false,
  "use-fresh-lr-scheduler": false,
  "learn-just-pooling": false,
  "checkpoint-last-n": 12,
  "log-every-n-steps": 10,
  "early-stop-patience": 3,
  "training-history": {
    "train-acc": [
      0.1604782882315922,
      0.3344241661422278,
      0.4119572057898049,
      0.4928886091881687,
      0.5403398363750787,
      0.5972309628697294,
      0.642039018250472,
      0.6748898678414097,
      0.6970421648835746,
      0.707488986784141,
      0.7329137822529893,
      0.7462555066079295,
      0.7497797356828194,
      0.7629955947136564,
      0.77293895531781,
      0.7685336689741976,
      0.782001258653241,
      0.7853996224040277,
      0.7906859660163625,
      0.7924480805538074
    ],
    "train-loss": [
      4.213185867684078,
      3.584047799323474,
      3.1875607201856515,
      2.8660419288860917,
      2.6430700322529894,
      2.464903732693518,
      2.337220490481435,
      2.2078289706576464,
      2.1194388176526116,
      2.057552411107615,
      1.9855800621460038,
      1.933304775999056,
      1.8796344005663939,
      1.849897734424166,
      1.8281122168030208,
      1.796006111351479,
      1.7762756155601007,
      1.7696869837555067,
      1.757290847230963,
      1.7476317898442417
    ],
    "val-acc": [
      0.30982367758186397,
      0.5006297229219143,
      0.5894206549118388,
      0.6920654911838791,
      0.6857682619647355,
      0.7216624685138538,
      0.7940806045340051,
      0.8236775818639799,
      0.8343828715365239,
      0.8343828715365239,
      0.853904282115869,
      0.8639798488664987,
      0.8885390428211587,
      0.8904282115869018,
      0.8853904282115869,
      0.9005037783375315,
      0.9080604534005038,
      0.9017632241813602,
      0.9036523929471033,
      0.906801007556675
    ],
    "val-loss": [
      3.448492534064526,
      2.714734217682173,
      2.2727283364729556,
      1.8896610936529992,
      1.6134749068796486,
      1.4307597975061281,
      1.2619428950683296,
      1.139624245577405,
      1.0248808065424637,
      1.0002830300658416,
      0.9026932100992959,
      0.8490386417027684,
      0.8113773272417354,
      0.7784534003444823,
      0.7686100037257076,
      0.7559375055978821,
      0.7210940217191086,
      0.7184167018615328,
      0.7097118656603756,
      0.7073098578553656
    ]
  },
  "fp16": false,
  "grad-scaler-config": {
    "init-scale": 8192,
    "growth-factor": 2.0,
    "backoff-factor": 0.5,
    "growth-interval": 100
  },
  "activation-clamp-value": 10000.0,
  "videomix-type": "spatial",
  "videomix-prob": 1,
  "use-augmentation": false,
  "method-name": "vita",
  "num-frame-tokens": 1,
  "num-heads-summary-attention": 12,
  "prompt-optimisation-method": "vita",
  "dataset": "ucf101",
  "data-dir": "/work3/fasco/data/raw/datasets/pevogam/ucf101/versions/1/UCF101/UCF-101",
  "model": "openai/clip-vit-base-patch16",
  "K-train": null,
  "K-val": null,
  "K-test": null,
  "val-examples-per-class": null,
  "batch-size": 4,
  "out": "/work3/fasco/data/processed/prompts/vita/ucf101",
  "num-workers": 2,
  "re-process-data": false,
  "use-wandb": true,
  "num-head-attention-pooling": 1,
  "N-text-layers": 12,
  "N-vision-layers": 12
}